# AI
AI related documents and projects
## How to setup a local LLM
You can setup using Ollama or LM Studio
How to setup in Ollama
1. Download software from https://ollama.com/search
2. Choose the right LLM model. For instance deepseek-r1:8b
3. To run a model: `ollama run deepseek-r1:8b`
4. To Exit/Stop ollama: `/bye`
5. To list all models: `ollama list`
6. ollama runs at: `http://localhost:11434`
7. To access in the code: `http://localhost:11434/api/chat`
